# Auto-filter-system-for-categorizing-frames
Our goal is to create a program that will be used as a camera auto filter for streamers. The benefit of this auto filter that the camera will automatically recognize the content that is taken and adapt the brightness, contrast or the focus accordingly. The program will tag different live video frames with category titles that represent what the streamer is currently podcasting. By looking at live streaming and video services like YouTube, there are about 300 hours of video content which are getting uploaded every minute worldwide with different categories. The top trending and most common categories are Gaming, Cooking, Music, Beauty &amp; Fashion and Comedy. Those videos usually have common patterns and setup which is showing a potential to automate tagging them with a category. To achieve this goal, we took out 20 frames in a similar distribution over the duration, from every video. We used roughly 22’000 pictures per category. 20’000 pictures used for training and the rest for validation. The program we wrote trains the surface layers of a pre trained model called “VGG 16” and then trains it on the defined categories. The new model tested with a collection of data that we separated from our training data. The best model has an accuracy of 91,8%. This accuracy was achieved by the 5th epoch. With only a few changes, the code can be adapted for more categories. The code we wrote can be found on GitHub and the link is in the appendix. The target of this program is to make the market of online video streaming smarter and more capable to cover the new live podcasting services that can have untagged streams.
